# -*- coding: utf-8 -*-
"""Gan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hcRK_YDqxhM1y1ZxWyxb-kKow3XpmvWN
"""


# import the library we will use
from table_evaluator import TableEvaluator
from ctgan import CTGANSynthesizer
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt


dataset = pd.read_csv('bank_term_deposit.csv', sep=';')
print(dataset.head())
raw_X = dataset.iloc[1:,1:16]
y = dataset.iloc[1:,16]
raw_X = raw_X.fillna(raw_X.mean())
print(raw_X.head())
print(dataset.shape)
job = dataset['duration']
#print(max(job))
plt.hist(job,bins = int(5000/10), label='origin',alpha=0.5)
#plt.show() 

# Identifies all the discrete columns
discrete_columns = [
    'job',
    'marital',
    'education',
    'default',
    'housing',
    'loan',
    'contact',
    'month',
    'poutcome',
]
ctgan = CTGANSynthesizer(epochs=10)
ctgan.fit(raw_X, discrete_columns)

#sample the synthetic data
synthetic_data = ctgan.sample(dataset.shape[0]-1)
print(synthetic_data.head(5))
syn = synthetic_data['duration']
plt.hist(syn,bins = int(5000/10),alpha=0.5,label='synthetic')
plt.legend(loc='upper right')
plt.xlabel('Duration')
plt.ylabel('Count')
print("origin mean, sd:",np.mean(job), np.std(job))

print("synthetic mean, sd:",np.mean(syn), np.std(syn))
plt.show() 
#print(synthetic_data)
"""
# table evaluation
table_evaluator = TableEvaluator(raw_X, synthetic_data)
table_evaluator.visual_evaluation()

# do some preprocessing, covert the category variable into dummy variable
from sklearn.preprocessing import LabelEncoder
lb_make = LabelEncoder()
for discrete_column in discrete_columns:
  raw_X[discrete_column] = lb_make.fit_transform(raw_X[discrete_column])
  synthetic_data[discrete_column] = lb_make.fit_transform(synthetic_data[discrete_column])

# split the data
X_train, X_test, y_train, y_test = train_test_split(raw_X,y,test_size = 0.25,random_state = 3)
S_X_train, S_X_test, S_y_train, S_y_test = train_test_split(synthetic_data,y,test_size = 0.25,random_state = 3)

# using Decision tree to predict
from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier(criterion ='entropy', random_state = 1)
classifier.fit(X_train, y_train)
# Predict the test set
y_pred = classifier.predict(X_test)

# Showing the accuracy rate and making the Confusion Matrix 
from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(y_test, y_pred)
accuracy = np.trace(matrix) / float(np.sum(matrix))
print("Cofusion Matrix for raw data")
print(matrix)
print("The accuracy is: {:.2%}".format(accuracy))

# using Decision tree to predict
classifier = DecisionTreeClassifier(criterion ='entropy', random_state = 1)
classifier.fit(S_X_train, S_y_train)
# Predict the test set
S_y_pred = classifier.predict(S_X_test)

# Showing the accuracy rate and making the Confusion Matrix 
from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(S_y_test, S_y_pred)
accuracy = np.trace(matrix) / float(np.sum(matrix))
print("Cofusion Matrix for synthetic data")
print(matrix)
print("The accuracy is: {:.2%}".format(accuracy))
"""